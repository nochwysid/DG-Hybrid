{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc_nb'></a> \n",
    "\n",
    "[Saving and Loading](#save_load)  \n",
    "[Dataloading](#data_load)  \n",
    "[Model Definition](#model_def)  \n",
    "[Evolution](#evol)  \n",
    "[Hybrid Loss](#hybrid)  \n",
    "[Train/Test function defs](#tt_def)  \n",
    "[Training](#train)  \n",
    "[Testing](#test)  \n",
    "[Visualization](#vis)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, json, jsonpickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CENSUS = 30\n",
    "tracking = np.zeros(shape=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='save_load'></a> \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Next ](#data_load) \n",
    "\n",
    "### Model Saving and loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for converting state_dict to JSON format\n",
    "def saveModel(model):\n",
    "    json_str = jsonpickle.encode(model.state_dict())\n",
    "    # Save best model for later use\n",
    "    out_file = open(\".json\", \"w\")\n",
    "    json.dump(json_str, out_file, indent = 6)\n",
    "    out_file.close()\n",
    "\n",
    "# Load saved model\n",
    "def loadModel():\n",
    "    in_file = open(\".json\", \"r\")\n",
    "    input = json.load(in_file)\n",
    "    thawed = jsonpickle.decode(input)\n",
    "    in_file.close()\n",
    "    return thawed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally should be at the top of the file\n",
    "#load = True\n",
    "load = False\n",
    "if load == True:\n",
    "    tmp_mdl.load_state_dict(loadModel())\n",
    "    for y in range(CENSUS):\n",
    "        model_list[y].copy(tmp_mdl)\n",
    "load = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#a = [0 for i in range(5)]\n",
    "import numpy as np\n",
    "a = np.zeros(shape=5)\n",
    "print(a)\n",
    "a[4] = 1\n",
    "print(a)\n",
    "for i in range(1,5):\n",
    "    a[i-1] = a[i]\n",
    "a[4] = 0\n",
    "print(a)\n",
    "for i in range(1,5):\n",
    "    a[i-1] = a[i]\n",
    "a[4] = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD: 0.4000000000000001, Var: 0.16000000000000006\n"
     ]
    }
   ],
   "source": [
    "print(f\"SD: {a.std()}, Var: {a.var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_load'></a> \n",
    "\n",
    "###### [Back to TOC](#toc_nb) [Previous ](#save_load) [Next ](#model_def) \n",
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1000, 784]) torch.Size([1000])\n",
      "<class 'torch.Tensor'> torch.Size([100, 784]) torch.Size([100])\n",
      "cuda:0\n",
      "Cell 1 Done\n"
     ]
    }
   ],
   "source": [
    "def load_data(path):\n",
    "    ds = pd.read_csv(path)\n",
    "    size = ds.shape[0]%64\n",
    "    features = torch.tensor(ds.iloc[:, 1:].values, \n",
    "                            dtype=torch.float32)\n",
    "    #features = torch.tensor(ds.iloc[:, 1:].values, \n",
    "    #                        dtype=torch.float32).reshape(ds.shape[0],28,28)\n",
    "    labels = torch.tensor(ds.iloc[:, 0].values, dtype=torch.float32)\n",
    "    print(type(features), features.shape,labels.shape)\n",
    "\n",
    "    #return torch.utils.data.TensorDataset(features, labels)\n",
    "    #return torch.utils.data.TensorDataset(torch.unsqueeze(features,dim=1),labels)\n",
    "    return features, labels\n",
    "       \n",
    "#training_data = load_data(\"~/Code_Folder/Datasets/mtrain-v2.csv\")\n",
    "#test_data = load_data(\"~/Code_Folder/Datasets/mtest-v2.csv\")\n",
    "train_feat, train_lbl = load_data(\"~/Code_files/Datasets/reduced_MNIST_train.csv\")\n",
    "train_feat = train_feat.to('cuda')\n",
    "train_lbl = train_lbl.to('cuda')\n",
    "test_feat, test_lbl = load_data(\"~/Code_files/Datasets/reduced_MNIST_test.csv\")\n",
    "test_feat = test_feat.to('cuda')\n",
    "test_lbl = test_lbl.to('cuda')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create data loaders.\n",
    "#train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "#print(train_dataloader,train_dataloader.dataset.__repr__())\n",
    "\n",
    "#test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#train_dataloader.features.to('cuda')\n",
    "#training_data.labels.to('cuda')\n",
    "#print(test_dataloader)\n",
    "#print(training_data.train_data.device)\n",
    "print(test_lbl.device)\n",
    "print(f\"Cell 1 Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_def'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#data_load) [Next ](#evol)  \n",
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the dropout? A separate forward func for dis and gen, \n",
    "# later, one func for both last layer problem and hybrid loss \n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, layers, activations):\n",
    "        super(MyNN, self).__init__()\n",
    "        \"\"\" Implement evolution of topology and weights \"\"\"\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) #input layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) #hidden layer\n",
    "        self.Dis = nn.Linear(hidden_size, output_size)\n",
    "        self.Gen = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # This allows making a variable size newtwork\n",
    "        # Next step is to figure out how to change the size dynamically during training\n",
    "        #self.layers = nn.ModuleList(layers)\n",
    "        #self.activations = nn.ModuleList(activations)\n",
    "        self.layers = []\n",
    "        for layer in layers:\n",
    "            if type(layer) == nn.Linear:\n",
    "                self.layer = layer.to('cuda')\n",
    "                self.layers.append(self.layer)\n",
    "        self.activations = activations \n",
    "        self.layeractivationpairs = zip(self.layers,self.activations)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x) #input layer\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(x.shape)\n",
    "        #print(\"forward is being called\")\n",
    "        dX = self.Dis(x)\n",
    "        gX = self.Gen(x)\n",
    "        #x = sm(x)\n",
    "        return dX, gX\n",
    "        #return x \n",
    "    \n",
    "    def altforward(self,x):\n",
    "        for layer,activation in self.layers,self.activations:\n",
    "            print(layer,activation)\n",
    "            print(layer.state_dict,activation.state_dict)\n",
    "            x = layer(x)\n",
    "            x = activation(x)\n",
    "        return x\n",
    "    \n",
    "    def copy(self, model):\n",
    "        self.load_state_dict(model.state_dict())\n",
    "    \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=4)\n",
    "\n",
    "\"\"\" Need a fitness function to decide to grow/shrink the network and layers within the network \"\"\"\n",
    "# Create an instance of the neural network\n",
    "input_size = 784\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "layers=[nn.Linear(784, 20),nn.Linear(20, 10)]\n",
    "activations=[nn.ReLU(),nn.ReLU()]\n",
    "\n",
    "# A list to hold the models\n",
    "model_list=[MyNN(input_size, hidden_size, output_size,layers, activations).to('cuda') for i in range(CENSUS)]\n",
    "\n",
    "# The temporary model for holding the current best weights and other params\n",
    "tmp_mdl = MyNN(input_size, hidden_size, output_size,layers, activations).to('cuda')\n",
    "#model_list=[MyNN(input_size, hidden_size, output_size).to('cuda') for i in range(CENSUS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evol'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#model_def) [Next ](#hybrid)  \n",
    "\n",
    "_What about model merging?_\n",
    "\n",
    "## Evolution  \n",
    "### Why evolution?   \n",
    " - Gradient descent is about hillclimbing (in reverse, mostly). It is more efficient that evoolution, but the best approaches can still get stuck in local minima. That is to say, there is no universal guarantee of finding the global minimum.  \n",
    " - Evolution is about tunneling. We don't know which direction we want to go, only that we don't want to go up. Copy yourself, and apply a mutation. The mutation is like teleporting your copy. If you find yourself inside a hill, try again. This is why it is inefficient. If you end up in a good spot, teleport your real self there.  \n",
    " - Use both. Use gradient descent to make quick progress initially. When progress slows, switch to evolution, when progress resumes, switch back.  \n",
    "### What is subject to the application of evolution?  \n",
    " - Gradient descent affects the weights only. There are helper parameter that control the way in which those weights are changed.  \n",
    " - For evolution, a similar kind of changes can be made, possibly also controled by helper parameters.  \n",
    "### How will it be implemented?  \n",
    " - Gradient descent is well established, with well known general advice or rules for getting good performance. Just follow those best practises.\n",
    " - Evolution is also well established, but not all good practices are needed. The important part is the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc(tensor):\n",
    "    vx,idxx = torch.max(tensor,1,keepdim=True)\n",
    "    vy,idxy = torch.max(tensor,0,keepdim=True)\n",
    "    #print(f\"\\nvx: {vx}, vy: {vy}\\n\")\n",
    "    x=int(torch.argmax(idxx))\n",
    "    y=int(torch.argmax(idxy))\n",
    "   # print(f\"idxx shape: {idxx.shape}, idxy shape: {idxy.shape}\")\n",
    "    #x=int(idxx[x,0])\n",
    "    #y=int(idxy[0,y])\n",
    "    ix=int(idxx[x,0])\n",
    "    iy=int(idxy[0,y])\n",
    "    #print(f\"idxx: {idxx}, idxy: {idxy}, \\nx: {x}, y: {y}, \\n{tensor}\\n\")\n",
    "    #print(f\"value: {tensor[iy,ix]} at y: {iy}, x: {ix}\")\n",
    "    #print(float(tensor[x][y]) )\n",
    "    return x,y\n",
    "\n",
    "def mutate(model_list):\n",
    "    \"\"\" Implement evolution of topology and weights \"\"\"\n",
    "    count=0\n",
    "    for model in model_list:\n",
    "        model.load_state_dict(model.state_dict())\n",
    "        size1=model.fc1.weight.shape # if shape doesn't work, try size, and may need to reshape\n",
    "        w1=model.fc1.weight.data.clone()\n",
    "        # renormalize the weights\n",
    "        x1,y1=loc(w1)\n",
    "        #print(w1[x1][y1])\n",
    "        #if w1[x1][y1]>1.0:\n",
    "        #    model.fc1.weight.data/=w1[x1][y1]\n",
    "\n",
    "        # Shift and scale ... is this a good idea?\n",
    "        model.fc1.weight.data = model.fc1.weight.data + ((torch.rand(size1)-0.5)/25).to('cuda')\n",
    "\n",
    "        size2=model.fc2.weight.shape\n",
    "        w2=model.fc2.weight.data.clone()\n",
    "        x2,y2=loc(w2)\n",
    "        if w2[x2][y2]>1.0:\n",
    "            model.fc2.weight.data/=w2[x2][y2]\n",
    "        model.fc2.weight.data = model.fc2.weight.data + ((torch.rand(size2)-0.5)/25).to('cuda')\n",
    "        \n",
    "        sizeD = model.Dis.weight.shape\n",
    "        wDis = model.Dis.weight.data.clone()\n",
    "        xD,yD=loc(wDis)\n",
    "        if wDis[xD][yD]>1.0:\n",
    "            model.Dis.weight.data/=wDis[xD][yD]\n",
    "        model.Dis.weight.data = model.Dis.weight.data + ((torch.rand(sizeD)-0.5)/25).to('cuda')\n",
    "        \n",
    "        sizeG = model.Gen.weight.shape\n",
    "        wGen = model.Gen.weight.data.clone()\n",
    "        xG,yG=loc(wGen)\n",
    "        if wGen[xG][yG]>1.0:\n",
    "            model.Gen.weight.data/=wGen[xG][yG]\n",
    "        model.Gen.weight.data = model.Gen.weight.data + ((torch.rand(sizeG)-0.5)/25).to('cuda')\n",
    "        \n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hybrid'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#evol) [Next ](#tt_def) \n",
    "### Hybrid Loss  \n",
    "This is where we give the details about the hybrid loss function. Benefits and limitations. Implementation details. Theory behind it.  \n",
    "\n",
    "#### Regularization  \n",
    "Due to the differences in the nature of the tasks, the weights may need regularization to not fall off the edge of reasonablenesses  \n",
    "#### Generative  \n",
    "To model the underlying data distribution. That is to say, the probablity of features, given the label. \n",
    "#### Discriminative  \n",
    "To model the likelihood of a sample coming from a distribution, given the features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.kl_loss = nn.KLDivLoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha  # Weight for KL\n",
    "        self.beta = beta    # Weight for Cross-Entropy\n",
    "\n",
    "    def forward(self, outputs, targets, aux_targets):\n",
    "        #Gloss = self.KLDivLoss()\n",
    "        # Compute KL Loss\n",
    "        kl = self.kl_loss(outputs, targets)\n",
    "        # Compute Cross-Entropy Loss\n",
    "        ce = self.ce_loss(outputs, aux_targets)\n",
    "        # Combine with weights\n",
    "        total_loss = self.alpha * kl + self.beta * ce\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is Claude Sonnet implementation\n",
    "class GMMLogisticLoss(nn.Module):\n",
    "    def __init__(self, n_components=2, n_features=784):\n",
    "        super(GMMLogisticLoss, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        # GMM parameters\n",
    "        self.means = nn.Parameter(torch.randn(n_components, n_features))\n",
    "        self.covs = nn.Parameter(torch.eye(n_features).repeat(n_components, 1, 1))\n",
    "        self.weights = nn.Parameter(torch.ones(n_components) / n_components)\n",
    "        \n",
    "        # Logistic loss\n",
    "        self.log_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def gmm_log_likelihood(self, x):\n",
    "        # Calculate GMM log likelihood for each component\n",
    "        log_probs = []\n",
    "        for k in range(self.n_components):\n",
    "            diff = x - self.means[k]\n",
    "            log_prob = -0.5 * (\n",
    "                torch.log(torch.det(self.covs[k])) +\n",
    "                torch.sum(torch.matmul(diff, torch.inverse(self.covs[k])) * diff, dim=1) +\n",
    "                self.n_features * np.log(2 * np.pi)\n",
    "            )\n",
    "            log_probs.append(log_prob + torch.log(self.weights[k]))\n",
    "        \n",
    "        return torch.logsumexp(torch.stack(log_probs), dim=0)\n",
    "\n",
    "    def forward(self, pred_dis, pred_gen, targets, features):\n",
    "        # Discriminative (Logistic) Loss\n",
    "        lr_loss = self.log_loss(pred_dis, targets)\n",
    "        \n",
    "        # Generative (GMM) Loss\n",
    "        gmm_loss = -torch.mean(self.gmm_log_likelihood(features))\n",
    "        \n",
    "        return lr_loss, gmm_loss\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, n_components=2, n_features=784):\n",
    "        super(HybridLoss, self).__init__()\n",
    "        self.alpha = alpha  # Weight between GMM and LR losses\n",
    "        self.gmm_lr_loss = GMMLogisticLoss(n_components=n_components, n_features=n_features)\n",
    "        \n",
    "    def forward(self, pred_dis, pred_gen, targets, features):\n",
    "        lr_loss, gmm_loss = self.gmm_lr_loss(pred_dis, pred_gen, targets, features)\n",
    "        total_loss = self.alpha * lr_loss + (1 - self.alpha) * gmm_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tt_def'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#hybrid) [Next ](#train) \n",
    "Test/Train Function defs  \n",
    "The eTrain function will also need to handle switching to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topscore=0.0\n",
    "# Initiate an empty array to hold the error values, probably needs to be a pytorch tensor\n",
    "# Use error history to determine when to switch between SGD and Evo\n",
    "def eTrain(model_list,ins,outs):\n",
    "    \"\"\" Implement switch back after improvement here\"\"\"\n",
    "    global topscore\n",
    "    hits=torch.zeros(CENSUS).to('cuda')\n",
    "    #print(f\"errs: {errs}, shape: {errs.shape}\")\n",
    "    for k in range(CENSUS):\n",
    "        #hit=0\n",
    "        miss=0\n",
    "        model=model_list[k] # kth model\n",
    "        for z in range(ins.shape[0]):# for each sample\n",
    "            #print(\"ins.shape[0] \" ,ins.shape)\n",
    "            #print(\"ins[0].shape[0] \" ,ins[0].shape)\n",
    "            p = model(ins[z].reshape(1,784))# class-wise predict. Need to change this to suit the model (Gen vs Dis)\n",
    "            t = torch.argmax(p)# position of max of class-wise predictions\n",
    "            gt = int(outs[z])\n",
    "            #print(f\"t: {t}, gt: {gt}\")\n",
    "            if t == gt:\n",
    "                hits[k] += 1\n",
    "            #y = torch.zeros(1,10).to('cuda')\n",
    "            #y[0,gt] = 1\n",
    "            #tmp = y - p\n",
    "            #print(tmp, gt, p.shape, y.shape)\n",
    "            #if torch.argmax(p)==torch.argmax(y):\n",
    "            #    score+=1\n",
    "    # Location in scoreboard of best model\n",
    "    best = int(torch.argmax(hits))\n",
    "    #print(f\"idx: {best}, count:\\n{hits},\\n\")\n",
    "    # The actual score of the best model\n",
    "    hit = int(hits[best])\n",
    "    t=100*hit/ins.shape[0]\n",
    "    if t>topscore:\n",
    "        topscore = t\n",
    "        print(f\"Train score: {topscore:.1f}\")\n",
    "    # Get the best model...\n",
    "    m1 = model_list[best]\n",
    "    #print(f\"t: {t}\")\n",
    "    # ...and set it aside\n",
    "    tmp_mdl.copy(m1)\n",
    "    \n",
    "    for y in range(CENSUS):\n",
    "        #model_list[y].copy(m1)\n",
    "        # Overwrite all models with the best one\n",
    "        model_list[y].copy(tmp_mdl)\n",
    "\n",
    "    # Perturb the weights a small amount and randomly\n",
    "    mutate(model_list=model_list)\n",
    "\n",
    "    #for model in model_list:\n",
    "    #    print(model.fc1.weight[0,:])\n",
    "    # The current best might still be the best, so reset the perturbed one back to the current best\n",
    "    model_list[best].copy(tmp_mdl)\n",
    "    #print(\"training...\")\n",
    "    # model_list[secondbest]=m2\n",
    "    #errs=torch.zeros(CENSUS,5).to('cuda')\n",
    "    #print(f\"models {best} with {hit} hits \")# and {secondbest} with {second} hits\")\n",
    "\n",
    "def SGDTrain(model_list,ins, outs, iter):\n",
    "    \"\"\" Implement threshold based switchover here \"\"\"\n",
    "    bestloss=1000.0\n",
    "    best=0\n",
    "    # Is this training a population of models, or just one?\n",
    "    for m in range(len(model_list)):\n",
    "        model = model_list[m]\n",
    "        ### Define a loss function and an optimizer\n",
    "        ##criterion = nn.CrossEntropyLoss()\n",
    "        ##Dloss = nn.CrossEntropyLoss()\n",
    "        ##Gloss = nn.KLDivLoss()\n",
    "\n",
    "        # Claude Sonnet\n",
    "        # Initialize the hybrid loss\n",
    "        criterion = HybridLoss(alpha=0.5, n_components=2, n_features=784)\n",
    "\n",
    "        #criterion = nn.MSELoss()\n",
    "        #optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        #optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "        avgloss = 0\n",
    "        for i in range(ins.shape[0]):\n",
    "            optimizer.zero_grad()\n",
    "            #predicted = model(ins[i].reshape(1,784))\n",
    "            dis_out, gen_out = model(ins[i].reshape(1, 784))\n",
    "            #loss = max(outs)*Dloss(predicted, outs[i]) + (1 - max(outs))*Gloss(predicted, outs[i])\n",
    "            #loss = criterion(predicted, outs[i])\n",
    "            loss = criterion(dis_out, gen_out, outs[i], ins[i].reshape(1, 784))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(avgloss)\n",
    "            avgloss+=loss.item()\n",
    "        if avgloss < bestloss:\n",
    "            bestloss = avgloss\n",
    "            best = m\n",
    "        #if iter % CENSUS==0:\n",
    "        #    print(f\" Loss: {avgloss/ins.shape[0]:.4f} at iter {iter}\")\n",
    "    #print(f\"Best loss: {bestloss/ins.shape[0]:.4f} at iter {iter}\")\n",
    "    m1 = model_list[best]\n",
    "    tmp_mdl.copy(m1)\n",
    "    for y in range(CENSUS):\n",
    "        model_list[y].copy(tmp_mdl)\n",
    "\n",
    "    mutate(model_list=model_list)\n",
    "    model_list[best].copy(tmp_mdl)\n",
    "    onelist = [tmp_mdl]\n",
    "    _ = model_test(onelist,test_feat,test_lbl)\n",
    "\n",
    "\n",
    "# Test the trained model\n",
    "#test_input = torch.randn(1, input_size).to('cuda')\n",
    "#with torch.no_grad():\n",
    "#    test_output = model(test_input)\n",
    "#print(\"Test output:\", test_output)\n",
    "\n",
    "def model_test(model_list,m_ins, m_outs):\n",
    "    print(m_ins.device)\n",
    "    scorelist = []\n",
    "    for model in model_list:\n",
    "        k = model_list.index(model)\n",
    "        score = 0\n",
    "\n",
    "        for i in range(m_ins.shape[0]):\n",
    "            p = model(m_ins[i].reshape(1,784))\n",
    "            gt = int(m_outs[i])\n",
    "            y = torch.zeros(1,10).to('cuda')\n",
    "            y[0,gt] = 1\n",
    "            tmp = y - p\n",
    "            #print(tmp, gt, p.shape, y.shape)\n",
    "            if torch.argmax(p)==torch.argmax(y):\n",
    "                score+=1\n",
    "        scorelist.append(score)\n",
    "        #print(f\"Model {k} result: {100*score/m_ins.shape[0]}%\")\n",
    "    #print()\n",
    "    scores = torch.Tensor(scorelist)\n",
    "    top = torch.argmax(scores)\n",
    "    #print(f\"Best result: {100*score/m_ins.shape[0]}%\")\n",
    "\n",
    "    print(f\"Best result: {100*scorelist[top]/m_ins.shape[0]}%\")\n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#tt_def) [Next ](#test) \n",
    "Training  \n",
    "The switching mechanism should be implemented here. A check after each epoch. Also, should maybe handle switching between losses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = model_test(model_list,test_feat,test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model_test(model_list,test_feat,test_lbl)\n",
    "\n",
    "EPOCHS = CENSUS\n",
    "#EPOCH = 8*CENSUS\n",
    "for i in range(EPOCHS):\n",
    "    eTrain(model_list,train_feat,train_lbl)\n",
    "    #SGDTrain(model_list,train_feat,train_lbl, i)\n",
    "    if i%20==0:\n",
    "        print(f\"Training {100*i/(EPOCHS):.1f}% completed\")\n",
    "    \n",
    "top = model_test(model_list,test_feat,test_lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(model_list[top])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='test'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#train) [Next ](#vis) \n",
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = torch.zeros(CENSUS)\n",
    "def model_test(model_list,ins, outs):\n",
    "    for model in model_list:\n",
    "        k = model_list.index(model)\n",
    "        score = 0\n",
    "\n",
    "        for i in range(ins.shape[0]):\n",
    "            tmp = model(ins[i])-outs[i]\n",
    "            if torch.argmax(model(ins[i]))==torch.argmax(outs[i]):\n",
    "                score+=1\n",
    "        \n",
    "        if int(100*score/ins.shape[0]) >= 80:\n",
    "            select[k] = int(100*score/ins.shape[0])\n",
    "\n",
    "        print(f\"Model {k} result: {100*score/ins.shape[0]}%\")\n",
    "\n",
    "model_test(model_list,test_in,test_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vis'></a>   \n",
    "\n",
    "###### [Back to TOC](#toc_nb)  [Previous ](#test) [Next ](#vis) \n",
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tmp_mdl.fc1.weight.cpu().detach()\n",
    "w2 = tmp_mdl.fc2.weight.cpu().detach()\n",
    "b1 = tmp_mdl.fc1.bias.cpu().detach()\n",
    "b2 = tmp_mdl.fc2.bias.cpu().detach()\n",
    "a = tmp_mdl.fc1.weight.cpu().detach()\n",
    "b = tmp_mdl.fc2.weight.cpu().detach()\n",
    "\n",
    "figure, WBplots = plt.subplots(2, 2)\n",
    "  \n",
    "# For Sine Function\n",
    "WBplots[0, 0].imshow(w1, cmap='hot', interpolation='nearest')\n",
    "WBplots[0, 0].set_title(\"1st layer weight\")\n",
    "  \n",
    "# For Cosine Function\n",
    "WBplots[0, 1].imshow(w2, cmap='hot', interpolation='nearest')\n",
    "WBplots[0, 1].set_title(\"2nd layer weight\")\n",
    "  \n",
    "# For Tangent Function\n",
    "WBplots[1, 0].imshow(b1, cmap='hot', interpolation='nearest')\n",
    "WBplots[1, 0].set_title(\"1st layer bias\")\n",
    "  \n",
    "# For Tanh Function\n",
    "WBplots[1, 1].imshow(b2, cmap='hot', interpolation='nearest')\n",
    "WBplots[1, 1].set_title(\"2nd layer bias\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the weights\n",
    "a = tmp_mdl.fc1.weight.cpu().detach()\n",
    "b = tmp_mdl.fc2.weight.cpu().detach()\n",
    "#a = model_list[2].fc1.weight.cpu().detach()\n",
    "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (torch.rand(4,4) - 0.5)/5\n",
    "print(c.max(),c.min())\n",
    "#print(a.max(),a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for model in model_list:\n",
    "    #json.dump(model)\n",
    "    print(json.dumps(model.toJSON()))\n",
    "    print(model, model.fc1.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list[0].__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_list[0](ins[1]),\"\\n\",outs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.Tensor.uniform_(0.,1.)\n",
    "tmax=test_input[0][torch.argmax(test_input[0])]\n",
    "print(test_input, test_input.shape,tmax)\n",
    "test_input = test_input/tmax\n",
    "print(test_input)\n",
    "test_input = test_input.to('cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
